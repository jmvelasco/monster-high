# Monster High API & Scraper

Este proyecto es una herramienta de extracci√≥n de datos (web scraper) dise√±ada para obtener informaci√≥n detallada sobre los personajes de *Monster High* desde su Wiki en Fandom. Adem√°s, integra inteligencia artificial (v√≠a Groq/Llama 3) para generar res√∫menes personalizados e infantiles de cada personaje.

## üöÄ Funcionalidades

- **Scraping de Personajes**: Extrae autom√°ticamente la lista completa de personajes desde la Wiki de Monster High.
- **Extracci√≥n de Detalles**: Obtiene informaci√≥n t√©cnica (infobox), im√°genes y secciones detalladas (biograf√≠a, relaciones, personalidad, etc.) de cada personaje.
- **Procesamiento con IA**: Utiliza la API de Groq (modelo `llama-3.1-8b-instant`) para generar cuentos/res√∫menes adaptados para una ni√±a de 6 a√±os (personalizado para "Cloe").
- **Persistencia de Datos**: Guarda toda la informaci√≥n procesada en archivos JSON estructurados localmente.

## üõ†Ô∏è Tecnolog√≠as

- **Node.js**: Entorno de ejecuci√≥n principal.
- **Axios**: Cliente HTTP para realizar las peticiones a la Wiki.
- **Cheerio**: Librer√≠a para parsear el HTML y extraer la informaci√≥n necesaria.
- **Groq SDK**: Cliente para conectar con modelos de lenguaje LLM (Llama 3).
- **Dotenv**: Gesti√≥n de variables de entorno.
- **TypeScript**: Superset de JavaScript que a√±ade tipos est√°ticos para un c√≥digo m√°s robusto.
- **Jest**: Framework de testing para pruebas unitarias.

## üìã Requisitos Previos

Antes de comenzar, aseg√∫rate de tener instalado:
- [Node.js](https://nodejs.org/) (v14 o superior recomendado)
- Una API Key de [Groq](https://groq.com/) para las funcionalidades de IA.

## üîß Instalaci√≥n

1. Clona este repositorio o descarga el c√≥digo.
2. Abre una terminal en la carpeta del proyecto.
3. Instala las dependencias:

```bash
npm install
```

## ‚öôÔ∏è Configuraci√≥n

Necesitas configurar tus credenciales para el servicio de IA.
1. Crea un archivo `.env` en la ra√≠z del proyecto (puedes basarte en el ejemplo si existe).
2. Agrega tu clave de API de Groq:

```env
GROQ_API_KEY=tu_clave_api_aqui
```

## üèÉ‚Äç‚ôÇÔ∏è Uso

El proyecto utiliza **TypeScript** y se puede ejecutar directamente usando `ts-node` o mediante scripts de `npm`.

### Ejecutar el Scraper
Para ejecutar el pipeline completo (scraping + IA + guardado):

```bash
npm start
```

### Comportamiento del Pipeline
El orquestador en `src/index.ts` realiza los siguientes pasos de forma automatizada:
1. **Escaneo**: Obtiene la lista completa de personajes.
2. **Extracci√≥n**: Itera sobre cada personaje para obtener sus detalles t√©cnicos y secciones.
3. **Magia con IA**: Env√≠a la informaci√≥n al `AIService` para generar un cuento personalizado para Cloe.
4. **Guardado Incremental**: Los resultados se guardan en tiempo real en `data/monster_high_features.json` usando el `JsonRepository`.

## üìÇ Estructura del Proyecto (Arquitectura Modular)

El c√≥digo ha sido refactorizado siguiendo principios **SOLID** y **DIP** (Inversi√≥n de Dependencias):

- `src/index.ts`: Punto de entrada y orquestador del pipeline.
- `src/config/`: Configuraci√≥n centralizada de URLs, API Keys y par√°metros de IA.
- `src/domain/`: Definici√≥n de interfaces y modelos de datos (Contratos).
- `src/services/`: Capa de servicios desacoplados.
  - `scraper/WikiScraper.ts`: L√≥gica de extracci√≥n HTML.
  - `ai/AIService.ts`: Adaptador para la API de Groq (Llama 3).
  - `storage/JsonRepository.ts`: Persistencia de datos en sistema de archivos.
- `src/utils/`: Utilidades generales (ej. sleep para rate limiting).

## üß™ Testing y Calidad (TDD)

Este proyecto sigue una metodolog√≠a de **Extreme Programming (XP)** y **Test-Driven Development (TDD)**. 

### Ejecutar Pruebas
Todos los servicios core est√°n cubiertos por tests unitarios que garantizan su correcto funcionamiento sin depender de servicios externos (No Mocks policy, usando Fakes).

```bash
npm test
```

### Cobertura
Se mantiene una cobertura superior al 85% en la l√≥gica de negocio. Los tests validan:
- Correcta extracci√≥n de datos HTML (WikiScraper).
- Manejo de errores y reintentos por rate limit (AIService).
- Gesti√≥n de archivos y directorios (JsonRepository).

## üìÑ Formato de Salida

Los datos se guardan en `data/monster_high_features.json` con el siguiente formato:

```json
{
  "nombre": "Draculaura",
  "url": "...",
  "imagen": "...",
  "info_tecnica": {
    "edad": "1600",
    "padres": "El Conde Dr√°cula"
  },
  "resumen_global": "¬°Hola Cloe! Draculaura es una vampiresa muy dulce...",
  "secciones": {
    "personalidad": {
      "car√°cter": ["Es muy dulce y amigable."]
    }
  }
}
```

## ‚ö†Ô∏è Nota Legal

Este proyecto es con fines educativos y de aprendizaje. El contenido extra√≠do pertenece a sus respectivos autores y a la comunidad de Fandom.

---

## üéì El Viaje de Refactorizaci√≥n: De Monolito a Modular (Caso de Estudio)

Este repositorio no solo es una herramienta funcional, sino tambi√©n un ejemplo pr√°ctico de c√≥mo aplicar ingenier√≠a de software para transformar c√≥digo "Legacy" en una arquitectura moderna y mantenible.

### üèõÔ∏è 1. El Punto de Partida: El Monolito
Originalmente, el proyecto era un archivo √∫nico en JavaScript. Aunque funcionaba, presentaba tres grandes retos:
*   **Acoplamiento Fuerte**: La l√≥gica de red estaba mezclada con el parseo HTML y la l√≥gica de negocio.
*   **Imposible de Testear**: Para probar cualquier cambio, era necesario realizar peticiones reales a Internet.
*   **Fragilidad**: Modificar el scraper pod√≠a romper accidentalmente la forma en que se guardaban los datos.

### üèóÔ∏è 2. La Transformaci√≥n: Principios Aplicados

Para resolver estos problemas, aplicamos los siguientes pilares de dise√±o:

#### **SOLID & Clean Code**
*   **S (Responsabilidad √önica)**: Cada clase tiene una misi√≥n clara (Scraper, AI, Storage).
*   **D (Inversi√≥n de Dependencias)**: Los servicios ya no crean sus herramientas (como Axios), sino que las "reciben" por el constructor. Esto nos permiti√≥ inyectar "Fakes" durante los tests para simular la red sin internet real.

#### **TDD (Test-Driven Development) & XP**
Seguimos una metodolog√≠a de **Extreme Programming**:
1.  **RED**: Escribimos el test que define el comportamiento deseado (y falla).
2.  **GREEN**: Escribimos el c√≥digo m√≠nimo para que el test pase.
3.  **REFACTOR**: Limpiamos y optimizamos el c√≥digo con la seguridad de que el test nos protege.

#### **No Mocks Policy**
En lugar de usar mocks t√©cnicos complejos que se acoplan a la implementaci√≥n, usamos **Objects Fakes** reales. Por ejemplo, un `FakeHttpClient` que se comporta como uno de verdad pero devuelve HTML est√°tico. Esto hace que nuestros tests sean m√°s robustos y documenten mejor el negocio.

### üîÑ 3. Comparativa Educativa

| Caracter√≠stica | Antes (Legacy JS) | Ahora (Modular TS) |
| :--- | :--- | :--- |
| **Confianza** | Manual ("Ojal√° no se rompa") | Alta (Tests autom√°ticos cubren ~90% de la l√≥gica) |
| **Legibilidad** | Un solo archivo denso | Estructura de carpetas por responsabilidades |
| **Evoluci√≥n** | Arriesgada | Segura mediante contratos definidos (Interfaces) |

Este proceso demuestra que **invertir en arquitectura no es perder tiempo, sino ganar velocidad y calidad** a largo plazo.
